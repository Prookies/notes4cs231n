### 训练前：合理性（Sanity）检查
#### 确定特定的正确损失值
在使用小参数进行初始化时，确保得到的损失值与预想的期望一致, 让正则化强度为0, 单独检查数据损失。
1. 如基于数据集CIFAR-10的Softmax分类器，一般期望它的初始损失值是2.302。这是因为初始时预计每个类别(共10类)的概率是0.1，对应Softmax损失值正确分类的负对数概率：-ln(0.1)=2.302
2. 对于Weston Watkins SVM，假设所有的边界都被越过（因为所有的分值都近似为零），所以损失值是9（因为对于每个错误分类，边界值是1）。
#### 提高正则化强度时导致损失值变大
#### 对小数据子集过拟合
在整个数据集进行训练之前，尝试在一个很小的数据集上进行训练（比如20个数据），确保能到达0的损失值。最好让正则化强度为0，不然不会得到0损失, 只有通过这一个正常性检查才能进行整个数据集训练。

### 训练中：跟踪多个重要数值
可视化重要数值是观察训练进程的一扇窗口，是直观理解不同的超参数设置效果的工具，从而知道如何修改超参数以获得更高效的学习过程。

注意：在图表中，x轴通常都是表示周期（epochs）单位，该单位衡量了在训练中每个样本数据都被观察过次数的期望, 一个周期意味着每个样本数据都被观察过了一次, 也就是这批数据对于模型的一次完整的训练。相较于迭代次数（iterations），一般更倾向跟踪周期，这是因为迭代次数与数据的批尺寸（batchsize）有关，而批尺寸的设置又可以是任意的。
#### 损失函数

![loss](image/loss.png)

过低的学习率会导致模型的改进几乎是线性的, 即模型优化的比较慢;过高的学习率会使得损失值下降很快, 但是最终的损失值却相对较高; 更高的学习率就会导致损失值上升, 因为导致了参数随机震荡；合适的学习率会使得损失值以一个比较恰当的速度下降, 最终的损失值也相对较低；损失值的震荡程度和批尺寸（batch size）有关，当批尺寸为1，震荡会相对较大, 当批尺寸就是整个数据集时震荡就会最小
#### 训练集与验证集准确率

![accuracy](image/accuracy.png)

在训练集准确率和验证集准确率中间的空隙指明了模型过拟合的程度：空隙过大说明模型过拟合，应该增大正则化强度, 更多的随机失活等方法或者收集更多的数据；空隙过小说明模型欠拟合, 应该增大参数数量使得模型更加复杂一些

#### 权重更新比例
权重中更新值的数量和全部权重的数量之间的比例, 需要对每个参数集的更新比例进行单独的计算和跟踪, 一个经验性的结论是这个比例应该在1e-3左右, 如果更低，说明学习率可能太小，如果更高，说明学习率可能太高。

#### 每层的激活数据与梯度分布

观察输出网络中所有层的激活数据和梯度分布的柱状图，任何奇怪的分布都不是好兆头。

#### 特征可视化

![特征可视化](image/特征可视化.png)

左图中的特征充满了噪音：网络没有收敛，学习率设置不恰当，正则化惩罚的权重过低。图的特征不错，平滑，干净而且种类繁多，说明训练过程进行良好。（特征图跟权重的关系是，每个权重即卷积核提取图像的一个特征图）